{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline using Logisitic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root_dir = '..\\data\\DUC2001'\n",
    "annotation_file = 'annotations.txt'\n",
    "txt_opn_tag = '<TEXT>'\n",
    "txt_close_tag = '</TEXT>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster_and_its_files(data_root_dir,annotation_file):\n",
    "    '''Get a Cluster and the file names associated with it\n",
    "       Returns a dictionary of the form { cluster_1 : [file1,file2,file3....], cluster_2 : [file1,file2,file3....] }'''    \n",
    "    \n",
    "    f = open(data_root_dir + '\\\\' + annotation_file,'r')\n",
    "    \n",
    "    clust_files = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for line in f.readlines():\n",
    "        cur_line = line.split(';')[0]\n",
    "        clust_name = cur_line.split('@')[1]\n",
    "        file_name = cur_line.split('@')[0]\n",
    "        \n",
    "        clust_files[clust_name].append(file_name)\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return clust_files\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AP900322-0200', 'FBIS-41815', 'FBIS-45908', 'FT921-9310', 'FT931-3883', 'FT933-8272', 'FT941-575', 'LA042290-0104', 'LA060490-0083', 'WSJ910107-0139']\n"
     ]
    }
   ],
   "source": [
    "print get_cluster_and_its_files(data_root_dir,annotation_file)['mad cow disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_from_doc(document_path,txt_opn_tag,txt_close_tag):\n",
    "    \n",
    "    f = open(document_path,'r')\n",
    "    content = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    start = content.index(txt_opn_tag) + len(txt_opn_tag)\n",
    "    end   = content.index(txt_close_tag)\n",
    "    \n",
    "    return content[start:end]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   Millions of gallons of crude oil that\\nspilled when a tanker ran aground spread across a wildlife-rich\\nstretch of ocean Saturday, and Alaska's chief environmental officer\\ncriticized cleanup efforts as too slow.\\n   The biggest oil spill in U.S. history created a slick about\\nseven miles long and seven miles wide in Prince William Sound. The\\nCoast Guard said only Reef Island and the western edge of Bligh\\nIsland had been touched by the slick.\\n   ``This situation, I think, was everyone's secret nightmare about\\nwhat could happen with oil traffic in the sound,'' said Dennis\\nKelso, commissioner of the Alaska Department of Environmental\\nConservation.\\n   Some 240,000 barrels _ about 10,080,000 gallons _ of crude oil\\nfrom Alaska's North Slope spilled early Friday when the 987-foot\\ntanker Exxon Valdez ran hard aground on Bligh Reef, about 25 miles\\noutside Valdez, where it had taken on a total cargo of 1.2 million\\nbarrels. Initial reports indicated 270,000 barrels had spilled.\\n   ``What we have here is a major environmental catastrophe,'' said\\none oil spill expert, Richard Golob of Boston, publisher of Golob\\nOil Pollution Bulletin.\\n   Golob said cleanup equipment at the site was ``grossly\\ninadequate'' but added that even under ideal circumstances cleanup\\nefforts would not have significantly reduced the spill's impact.\\n   ``It is an enclosed body of water,'' he said. ``The only way for\\nthis oil to ecape out to the sea is by traversing the entire length\\nof Prince William Sound with all its islands, fjords and bays and\\nchannels.\\n   ``And during that transit, undoubtedly a large stretch of\\nshoreline will be contaminated,'' he said.\\n   Divers Saturday said they had found six to eight holes in the\\nvessel's hull large enough to swim through, said Frank Iarossi,\\npresident of Exxon Shipping Co. About 30 feet of the vessel is\\nresting on a shelf on the reef.\\n   Efforts to begin pumping 200,000 gallons of oil off the Exxon\\nValdez onto another tanker, the Exxon Baton Rouge, were halted\\nearly Saturday when authorities noticed that oil appeared to\\nleaking as the pumping operation proceeded.\\n   Eleven of 17 tanks that lie forward of the ship's masthead were\\nruptured in the accident, causing concern over removal of the oil,\\nsaid Coast Guard Lt. Ed Wieliczkiewicz.\\n   ``Whenever you start removing oil from a vessel this size it has\\nto be done in a controlled manner,'' Wieliczkiewicz said. ``If it's\\nnot ... you endanger the stability of the vessel.''\\n   Wieliczkiewicz said a boom was placed around the Exxon Valdez\\nand the Exxon Baton Rouge to help contain oil around the vessels.\\n   He also said four members of the Coast Guard's Pacific Strike\\nTeam from San Francisco, specially trained to deal with pollution\\nand oil spills, arrived Saturday and were helping to rig pumps and\\nassemble equipment needed to transfer oil to the Baton Rouge.\\n   Kelso was highly critical of what he said was a slow response to\\nthe spill.\\n   ``The initial reponse was inadequate and unacceptable,'' he said\\nbefore a news conference Saturday. Kelso said the efforts should\\nhave been under way in five hours, but took much longer. ``You miss\\nthe opportunity right at the beginning and you've missed our best\\nopportunity to do something.''\\n   Kelso said Alaska has a plan for oil spills that calls for\\naction within five hours of a spill. It took several hours longer,\\nhe said, and only two of seven skimmers available to the Alyeska\\nPipeline Service Co. were used at the outset.\\n   Alyeska spokesman Chuck O'Donnel said he was satisfied with his\\ncompany's actions. ``I think our people did an excellent job,'' he\\nsaid.\\n   The spill's effect on wildlife had not yet been assessed, but\\ncommercial fishermen who depend on the sound for a catch worth\\nmillions of dollars were outraged and said a key herring spawning\\narea had been polluted.\\n   ``The whole food chain could be affected by the spill,'' said\\nAlan Reichman, ocean ecology coordinator for the environmental\\ngroup Greenpeace, in Seattle.\\n   ``There's a high concentration of sea otter, waterfowl, sea\\nbirds and pink salmon in that area,'' said Steve Goldstein, a\\nspokesman for the Interior Department in Washington. ``Some birds\\nhave already died, and we are doing our best to try to save the\\nfish by containing the oil to the area where it presently is and by\\ntrying to skim it.''\\n   Whales, porpoises and seals are also common in Prince William\\nSound. ``It's kind of like sailing through a zoo,'' said Jim\\nLethcoe, who lives on a boat in the sound and operates a sailing\\nbusiness.\\n   An animal cleanup station was set up in a building at the\\ncommunity college in Valdez, but volunteers there said they had no\\nanimals to work on by midafternoon.\\n   The response to the spill also drew fire from the 12,000-member\\nUnited Fishermen of Alaska.\\n   ``We feel that this should have been the easiest oil spill in\\nthe world to clean up,'' said Riki Ott, chairman of the\\norganization's habitat committee. She noted that the spill had\\noccurred in a protected area close to the Valdez marine terminal\\nand the water was calm.\\n   Ott said the spill had polluted Prince William Sound's primary\\nherring spawning area. Fishermen also take salmon and shellfish\\nfrom the sound. Last year, they were paid about $85 million for\\ntheir catches, she said.\\n   The Port of Valdez remained closed to tanker traffic. North\\nSlope crude oil is shipped 800 miles through the trans-Alaska oil\\npipeline from Prudhoe Bay south to Valdez for shipment aboard\\ntankers to refineries outside Alaska.\\n   The Coast Guard said the Exxon Valdez struck the reef when it\\nmaneuvered outside normal tanker traffic lanes to avoid icebergs.\\n   The vessel's captain, Joseph Hazelwood, has worked for Exxon for\\n20 years, at least 10 as a ship's master. It was unclear if a pilot\\nwas aboard the Exxon Valdez when it grounded.\\n   There was no decision Saturday on whether to use chemicals to\\ndisperse the oil, but a test of the dispersal method was being\\nconducted Saturday afternoon, as was a test to determine whether at\\nleast some of the crude oil could be burned.\\n   Coast Guard Cmdr. Steven McCall said National Transportation\\nSafety Board investigators are expected to arrive Sunday to take\\nover the accident probe.\\n   He said one or more blood-alcohol tests were administered after\\nthe grounding, but he said he didn't know know how many people were\\ntested or the results. McCall said the tests routinely are\\nadministered in marine accidents involving federal jurisdiction.\\n   The Coast Guard issued a statement late Saturday that McCall has\\nsubpoenaed the ship's master and two crew members.\\n   The subpoenas require them to make themselves available to NTSB\\ninvestigators arriving Sunday. The Coast Guard said the supoenas\\nwere routine.\\n   Previously, the largest U.S. tanker spill was the Dec. 15, 1976,\\ngrounding of the Argo Merchant tanker off the Nantucket shoals off\\nMassachusetts, in which 7.6 million gallons of oil spilled, Golob\\nsaid.\\n   Up to 10.7 million gallons of oil was lost on Nov. 1, 1979, when\\nthe tanker Burmah Agate collided with another ship in Galveston\\nBay, Texas. However, that oil burned as well as spilled.\\n   The largest tanker spill in history resulted from the July 19,\\n1979, collision off Tobago of the supertankers Atlantic Empress and\\nAegean Captain, in which 300,000 tons _ more than 80 million\\ngallons _ of oil was lost.\\n\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'AP830325-0143'\n",
    "file_path = data_root_dir + '\\\\' + file_name\n",
    "get_text_from_doc(file_path,txt_opn_tag,txt_close_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_txt(text):\n",
    "    \n",
    "    tokenizedList = re.split('\\W+', text.lower())\n",
    "    return [x for x in tokenizedList if x != '' and x != '\\n' and x != u'\\x85' and x != '\\r']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'this', 'is', 'this', 'cool', 'i', 'don', 't', 'know']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_txt('What is this ?? Is this cool ? I don\\'t know')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature 1 : Term frequency over the cluster(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_term_freqs(data_root_dir,annotation_file,stop_words=None) :\n",
    "    '''Get the term freqs of words in clusters. The term freqs are unique to clusters.\n",
    "    Returns a dict of form {clust1 : {word1 : 2, word2 :3...},clust2 : {word1 : 2, word2 :3..} ......}'''\n",
    "        \n",
    "    #Check about stop_words\n",
    "    \n",
    "    clust_files = get_cluster_and_its_files(data_root_dir,annotation_file)\n",
    "    \n",
    "    clust_term_freq = defaultdict(defaultdict)\n",
    "    \n",
    "    \n",
    "    for clust,files in clust_files.iteritems():\n",
    "        term_freq = defaultdict(int)\n",
    "        \n",
    "        for doc in files:\n",
    "            doc_path = data_root_dir + '\\\\' + doc\n",
    "            txt = get_text_from_doc(doc_path,txt_opn_tag,txt_close_tag)\n",
    "            doc_tokens = tokenize_txt(txt)\n",
    "            \n",
    "            for token in doc_tokens:\n",
    "                term_freq[token] += 1\n",
    "        \n",
    "        clust_term_freq[clust] = term_freq\n",
    "    \n",
    "    return clust_term_freq\n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'all': 1, 'german': 4, '092': 1, 'existing': 1, 'per': 1, 'human': 1, 'still': 1, 'decisions': 1, 'its': 1, 'contaminated': 3, 'one': 1, 'had': 2, 'kretzschmar': 1, 'to': 6, 'jakob': 1, 'do': 1, 'non': 2, 'popularly': 1, 'march': 1, 'diseases': 1, 'than': 1, 'government': 1, 'very': 1, 'scientists': 1, 'possible': 1, 'cannot': 1, 'know': 1, 'not': 2, 'affect': 2, 'safeguards': 1, 'countries': 1, 'should': 1, 'medicines': 1, '50': 1, 'transmitted': 2, 'minimal': 1, 'ban': 2, 'university': 1, 'because': 1, 'humans': 4, 'bovine': 1, 'connections': 1, 'likely': 1, 'catching': 1, 'are': 1, 'encephalopathy': 1, 'eu': 2, 'further': 1, 'institutes': 1, 'agriculture': 1, 'britain': 2, 'concern': 1, 'universities': 1, 'project': 1, 'said': 3, 'imported': 3, 'for': 2, '1992': 1, 'recorded': 1, 'expressed': 1, 'research': 4, 'may': 1, 'gottingen': 1, 'health': 1, 'between': 1, 'new': 1, 'announced': 1, 'available': 1, 'be': 7, 'we': 1, 'pushing': 1, 'however': 1, 'switzerland': 1, 'were': 3, 'from': 4, '100': 1, 'by': 2, 'official': 1, 'on': 2, 'about': 1, 'last': 1, 'would': 1, 'origins': 1, 'launch': 1, 'of': 11, '30': 1, 'discussed': 1, 'british': 4, 's': 2, 'figures': 1, 'existent': 2, 'germany': 2, 'argue': 1, 'or': 2, 'comes': 1, 'danger': 1, 'creutzfeldt': 1, 'year': 1, 'ministers': 2, 'beings': 1, 'initiative': 1, 'been': 1, 'straussler': 1, 'rarely': 1, 'gerstmann': 1, 'beef': 6, 'debilitates': 1, 'union': 2, 'there': 2, 'two': 2, 'cent': 1, '2': 2, 'way': 1, 'meeting': 1, 'more': 1, 'spongiform': 1, 'that': 8, 'brains': 1, 'sufficient': 1, 'but': 1, 'personally': 1, 'known': 2, 'cases': 2, 'with': 1, 'eat': 1, '13': 1, 'made': 2, 'animals': 1, 'cow': 2, 'transmissible': 1, 'whether': 1, 'ministry': 2, 'as': 3, 'will': 2, 'can': 2, 'country': 2, 'result': 1, 'and': 6, 'seven': 1, 'imports': 2, 'is': 4, 'cattle': 3, 'it': 2, 'evidence': 1, 'examine': 2, 'at': 1, 'have': 1, 'in': 4, 'affected': 1, 'technology': 1, 'any': 1, 'syndrome': 1, 'no': 1, 'other': 2, 'take': 1, 'which': 3, 'several': 1, 'european': 1, 'arguing': 1, 'who': 2, 'yesterday': 1, '000': 1, 'sponsored': 1, 'mad': 1, 'hans': 1, 'bse': 5, 'died': 1, 'conclusive': 1, 'a': 8, 'i': 1, 'professor': 1, 'ingredients': 1, 'disease': 5, 'think': 1, 'veal': 1, 'tonnes': 2, 'the': 15})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_term_freqs(data_root_dir,annotation_file)['cattle disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Feature 2 : Total document number in the datasets, divided by the frequency of documents which contains this word (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_doc_freqs(data_root_dir,annotation_file):\n",
    "    data_root_dir += '\\\\'\n",
    "    \n",
    "    docs =  [file_name for _,__,file_name in os.walk(data_root_dir)][0]\n",
    "    \n",
    "    if annotation_file in docs:\n",
    "        docs.remove(annotation_file)        \n",
    "    \n",
    "    inverted_index  = defaultdict(set)\n",
    "    \n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_path = data_root_dir + doc        \n",
    "        txt = get_text_from_doc(doc_path,txt_opn_tag,txt_close_tag)\n",
    "        doc_tokens = tokenize_txt(txt)\n",
    "        \n",
    "        for token in doc_tokens:\n",
    "            inverted_index[token].add(doc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    no_of_docs = len(docs)\n",
    "    idf_dict = defaultdict(float)\n",
    "    \n",
    "    for term,doc_lst in inverted_index.iteritems():\n",
    "        idf_dict[term] = float(no_of_docs) / len(doc_lst)\n",
    "    \n",
    "    return idf_dict\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.5\n",
      "1.00324675325\n"
     ]
    }
   ],
   "source": [
    "doc_freqs = get_doc_freqs(data_root_dir,annotation_file)\n",
    "print doc_freqs['furazabol']\n",
    "print doc_freqs['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
